{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/transformers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gr-qc/0612006v1',\n",
       " '1310.1984v2',\n",
       " '1605.08683v1',\n",
       " '1403.2188v1',\n",
       " '2204.07780v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"Transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        print(item)\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        print(item_path)\n",
    "        \n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            print(file_path)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_in_transformer\n",
      "papers/attention_in_transformer\n",
      "papers/attention_in_transformer/papers_info.json\n",
      "{\n",
      "  \"title\": \"Simulating Hard Attention Using Soft Attention\",\n",
      "  \"authors\": [\n",
      "    \"Andy Yang\",\n",
      "    \"Lena Strobl\",\n",
      "    \"David Chiang\",\n",
      "    \"Dana Angluin\"\n",
      "  ],\n",
      "  \"summary\": \"We study conditions under which transformers using soft attention can\\nsimulate hard attention, that is, effectively focus all attention on a subset\\nof positions. First, we examine several subclasses of languages recognized by\\nhard-attention transformers, which can be defined in variants of linear\\ntemporal logic. We demonstrate how soft-attention transformers can compute\\nformulas of these logics using unbounded positional embeddings or temperature\\nscaling. Second, we demonstrate how temperature scaling allows softmax\\ntransformers to simulate general hard-attention transformers, using a\\ntemperature that depends on the minimum gap between the maximum attention\\nscores and other attention scores.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/2412.09925v2\",\n",
      "  \"published\": \"2024-12-13\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(extract_info('2412.09925v2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [\n",
    "#     {\n",
    "#         \"name\": \"search_papers\",\n",
    "#         \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "#         \"input_schema\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"topic\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The topic to search for\"\n",
    "#                 }, \n",
    "#                 \"max_results\": {\n",
    "#                     \"type\": \"integer\",\n",
    "#                     \"description\": \"Maximum number of results to retrieve\",\n",
    "#                     \"default\": 5\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"topic\"]\n",
    "#         }\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"extract_info\",\n",
    "#         \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "#         \"input_schema\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"paper_id\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The ID of the paper to look for\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"paper_id\"]\n",
    "#         }\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88983eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OPENAI\n",
    "\n",
    "# Convert your existing tools to OpenAI format\n",
    "tools_openai = [\n",
    "    {\n",
    "        \"type\": \"function\",  # This is required for OpenAI\n",
    "        \"function\": {\n",
    "            \"name\": \"search_papers\",\n",
    "            \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "            \"parameters\": {  # Note: \"parameters\" instead of \"input_schema\"\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The topic to search for\"\n",
    "                    }, \n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to retrieve\",\n",
    "                        \"default\": 5\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_info\",\n",
    "            \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"paper_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ID of the paper to look for\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"paper_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018d1c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "# client = anthropic.Anthropic(api_key=\"\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Python function `process_query(query)` seems to be handling a conversation between a user and an assistant using a messaging system. Here's a breakdown of what it does:\n",
    "\n",
    "# Main functionalities:\n",
    "# - Processes user queries and interacts with Claude AI model\n",
    "# - Handles both text responses and tool usage\n",
    "# - Executes tools and feeds results back to the conversation\n",
    "# - Maintains conversation flow until query is fully processed\n",
    "# - Prints assistant responses and tool execution details\n",
    "# - Operates in a stateless manner (no memory between queries)\n",
    "\n",
    "\n",
    "\n",
    "# def process_query(query):\n",
    "    \n",
    "#     messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "#     response = client.messages.create(max_tokens = 2024,\n",
    "#                                   model = 'claude-3-7-sonnet-20250219', \n",
    "#                                   tools = tools,\n",
    "#                                   messages = messages)\n",
    "    \n",
    "    \n",
    "#     process_query = True\n",
    "#     while process_query:\n",
    "#         assistant_content = []\n",
    "\n",
    "#         for content in response.content:\n",
    "#             if content.type == 'text':\n",
    "                \n",
    "#                 print(content.text)\n",
    "#                 assistant_content.append(content)\n",
    "                \n",
    "#                 if len(response.content) == 1:\n",
    "#                     process_query = False\n",
    "            \n",
    "#             elif content.type == 'tool_use':\n",
    "                \n",
    "#                 assistant_content.append(content)\n",
    "#                 messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "#                 tool_id = content.id\n",
    "#                 tool_args = content.input\n",
    "#                 tool_name = content.name\n",
    "#                 print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "#                 result = execute_tool(tool_name, tool_args)\n",
    "#                 messages.append({\"role\": \"user\", \n",
    "#                                   \"content\": [\n",
    "#                                       {\n",
    "#                                           \"type\": \"tool_result\",\n",
    "#                                           \"tool_use_id\": tool_id,\n",
    "#                                           \"content\": result\n",
    "#                                       }\n",
    "#                                   ]\n",
    "#                                 })\n",
    "#                 response = client.messages.create(max_tokens = 2024,\n",
    "#                                   model = 'claude-3-7-sonnet-20250219', \n",
    "#                                   tools = tools,\n",
    "#                                   messages = messages) \n",
    "                \n",
    "#                 if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "#                     print(response.content[0].text)\n",
    "#                     process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef6b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        max_tokens=2024,\n",
    "        model='gpt-4o',  # or other models like 'gpt-4-turbo', 'gpt-3.5-turbo'\n",
    "        tools=tools_openai,  # Assumes 'tools' is defined in the outer scope\n",
    "        tool_choice='auto',  # Let the model decide whether to use tools\n",
    "        messages= [{'role': 'user', 'content': \"What is your name?\"}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a97218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ByoDplrZBeRXrLN8MEUfNFYVR9YjX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am ChatGPT, a language model created by OpenAI.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1753832433, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_07871e2ad8', usage=CompletionUsage(completion_tokens=14, prompt_tokens=121, total_tokens=135, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2ed2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Extract information about 2412.09925v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fefc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the conversation with the user query\n",
    "messages = [{'role': 'user', 'content': query}]\n",
    "\n",
    "# Make the initial API call to OpenAI\n",
    "response = client.chat.completions.create(\n",
    "    max_tokens=2024,\n",
    "    model='gpt-4o',  # or other models like 'gpt-4-turbo', 'gpt-3.5-turbo'\n",
    "    tools=tools_openai,  # Assumes 'tools' is defined in the outer scope\n",
    "    tool_choice='auto',  # Let the model decide whether to use tools\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2b22f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_XLYvN166eEwYISOm8siH43C6', function=Function(arguments='{\"paper_id\":\"2412.09925v2\"}', name='extract_info'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "assistant_message = response.choices[0].message\n",
    "# print(assistant_message.content)\n",
    "print(assistant_message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6378aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(assistant_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1389835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the assistant's message to conversation history\n",
    "messages.append({\n",
    "    'role': 'assistant',\n",
    "    'content': assistant_message.content,\n",
    "    'tool_calls': assistant_message.tool_calls\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd0f212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Extract information about 2412.09925v2'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_XLYvN166eEwYISOm8siH43C6', function=Function(arguments='{\"paper_id\":\"2412.09925v2\"}', name='extract_info'), type='function')]}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb1cde0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tool extract_info with args {'paper_id': '2412.09925v2'}\n",
      "attention_in_transformer\n",
      "papers/attention_in_transformer\n",
      "papers/attention_in_transformer/papers_info.json\n"
     ]
    }
   ],
   "source": [
    "# Process each tool call\n",
    "for tool_call in assistant_message.tool_calls:\n",
    "    tool_id = tool_call.id\n",
    "    tool_name = tool_call.function.name\n",
    "    # OpenAI provides arguments as a JSON string, so we need to parse it\n",
    "    tool_args = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "    \n",
    "    # Execute the tool (assumes execute_tool function is defined elsewhere)\n",
    "    result = execute_tool(tool_name, tool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "272a08fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Simulating Hard Attention Using Soft Attention\",\n",
      "  \"authors\": [\n",
      "    \"Andy Yang\",\n",
      "    \"Lena Strobl\",\n",
      "    \"David Chiang\",\n",
      "    \"Dana Angluin\"\n",
      "  ],\n",
      "  \"summary\": \"We study conditions under which transformers using soft attention can\\nsimulate hard attention, that is, effectively focus all attention on a subset\\nof positions. First, we examine several subclasses of languages recognized by\\nhard-attention transformers, which can be defined in variants of linear\\ntemporal logic. We demonstrate how soft-attention transformers can compute\\nformulas of these logics using unbounded positional embeddings or temperature\\nscaling. Second, we demonstrate how temperature scaling allows softmax\\ntransformers to simulate general hard-attention transformers, using a\\ntemperature that depends on the minimum gap between the maximum attention\\nscores and other attention scores.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/2412.09925v2\",\n",
      "  \"published\": \"2024-12-13\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "929ee1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_id,\n",
    "                    \"content\": json.dumps(result) if not isinstance(result, str) else result\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5593255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Extract information about 2412.09925v2'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_XLYvN166eEwYISOm8siH43C6', function=Function(arguments='{\"paper_id\":\"2412.09925v2\"}', name='extract_info'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_XLYvN166eEwYISOm8siH43C6',\n",
       "  'content': '{\\n  \"title\": \"Simulating Hard Attention Using Soft Attention\",\\n  \"authors\": [\\n    \"Andy Yang\",\\n    \"Lena Strobl\",\\n    \"David Chiang\",\\n    \"Dana Angluin\"\\n  ],\\n  \"summary\": \"We study conditions under which transformers using soft attention can\\\\nsimulate hard attention, that is, effectively focus all attention on a subset\\\\nof positions. First, we examine several subclasses of languages recognized by\\\\nhard-attention transformers, which can be defined in variants of linear\\\\ntemporal logic. We demonstrate how soft-attention transformers can compute\\\\nformulas of these logics using unbounded positional embeddings or temperature\\\\nscaling. Second, we demonstrate how temperature scaling allows softmax\\\\ntransformers to simulate general hard-attention transformers, using a\\\\ntemperature that depends on the minimum gap between the maximum attention\\\\nscores and other attention scores.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2412.09925v2\",\\n  \"published\": \"2024-12-13\"\\n}'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ba6a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "                max_tokens=2024,\n",
    "                model='gpt-4o',\n",
    "                tools=tools_openai,\n",
    "                tool_choice='auto',\n",
    "                messages=messages\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77572240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79860d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper titled **\"Simulating Hard Attention Using Soft Attention\"** is authored by Andy Yang, Lena Strobl, David Chiang, and Dana Angluin. Here is a summary of the paper:\n",
      "\n",
      "The study explores conditions under which transformers using soft attention can simulate hard attention, meaning they can effectively focus all attention on a subset of positions. The research particularly examines several subclasses of languages recognized by hard-attention transformers, which can be described using variants of linear temporal logic. The paper demonstrates methods for how soft-attention transformers can compute formulas of these logics by employing unbounded positional embeddings or temperature scaling. Furthermore, it shows how temperature scaling enables softmax transformers to simulate general hard-attention transformers, by using a temperature that is dependent on the minimum gap between the maximum attention scores and other attention scores.\n",
      "\n",
      "- **Published Date:** December 13, 2024\n",
      "- **PDF URL:** [Simulating Hard Attention Using Soft Attention PDF](http://arxiv.org/pdf/2412.09925v2)\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670abc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import anthropic\n",
    "\n",
    "# load_dotenv()\n",
    "# anthropic = anthropic.Anthropic()\n",
    "\n",
    "# def process_query(query):\n",
    "#     messages = [{'role':'user', 'content':query}]\n",
    "#     response = anthropic.messages.create(max_tokens = 2024,\n",
    "#                                   model = 'claude-3-7-sonnet-20250219', \n",
    "#                                   tools = tools,\n",
    "#                                   messages = messages)\n",
    "#     process_query = True\n",
    "#     while process_query:\n",
    "#         assistant_content = []\n",
    "#         for content in response.content:\n",
    "#             if content.type =='text':\n",
    "#                 print(content.text)\n",
    "#                 assistant_content.append(content)\n",
    "#                 if(len(response.content)==1):\n",
    "#                     process_query= False\n",
    "#             elif content.type == 'tool_use':\n",
    "#                 assistant_content.append(content)\n",
    "#                 messages.append({'role':'assistant', 'content':assistant_content})\n",
    "#                 tool_id = content.id\n",
    "#                 tool_args = content.input\n",
    "#                 tool_name = content.name\n",
    "\n",
    "#                 print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "#                 # Call a tool\n",
    "#                 result = execute_tool(tool_name, tool_args)\n",
    "#                 messages.append({\"role\": \"user\", \n",
    "#                                   \"content\": [\n",
    "#                                       {\n",
    "#                                           \"type\": \"tool_result\",\n",
    "#                                           \"tool_use_id\":tool_id,\n",
    "#                                           \"content\": result\n",
    "#                                       }\n",
    "#                                   ]\n",
    "#                                 })\n",
    "#                 response = anthropic.messages.create(max_tokens = 2024,\n",
    "#                                   model = 'claude-3-7-sonnet-20250219', \n",
    "#                                   tools = tools,\n",
    "#                                   messages = messages) \n",
    "                \n",
    "#                 if(len(response.content)==1 and response.content[0].type == \"text\"):\n",
    "#                     print(response.content[0].text)\n",
    "#                     process_query= False\n",
    "\n",
    "\n",
    "# def chat_loop():\n",
    "#     print(\"Type your queries or 'quit' to exit.\")\n",
    "#     while True:\n",
    "#         try:\n",
    "#             query = input(\"\\nQuery: \").strip()\n",
    "#             if query.lower() == 'quit':\n",
    "#                 break\n",
    "    \n",
    "#             process_query(query)\n",
    "#             print(\"\\n\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a1551cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI  # Import the OpenAI client library\n",
    "\n",
    "def process_query(query):\n",
    "    \"\"\"\n",
    "    Process a user query using OpenAI's GPT model, handling both text responses and tool calls.\n",
    "    This function maintains a conversation flow until the query is fully processed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the conversation with the user query\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    # Make the initial API call to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        max_tokens=2024,\n",
    "        model='gpt-4o',  # or other models like 'gpt-4-turbo', 'gpt-3.5-turbo'\n",
    "        tools=tools_openai,  # Assumes 'tools' is defined in the outer scope\n",
    "        tool_choice='auto',  # Let the model decide whether to use tools\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        # Get the assistant's message from the response\n",
    "        assistant_message = response.choices[0].message\n",
    "        \n",
    "        # Check if the assistant is using tools or providing a text response\n",
    "        if assistant_message.tool_calls:\n",
    "            # Assistant wants to use tools\n",
    "            \n",
    "            # If there's any text content alongside the tool calls, print it\n",
    "            if assistant_message.content:\n",
    "                print(assistant_message.content)\n",
    "            \n",
    "            # Add the assistant's message to conversation history\n",
    "            messages.append({\n",
    "                'role': 'assistant',\n",
    "                'content': assistant_message.content,\n",
    "                'tool_calls': assistant_message.tool_calls\n",
    "            })\n",
    "            \n",
    "            # Process each tool call\n",
    "            for tool_call in assistant_message.tool_calls:\n",
    "                tool_id = tool_call.id\n",
    "                tool_name = tool_call.function.name\n",
    "                # OpenAI provides arguments as a JSON string, so we need to parse it\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                # Execute the tool (assumes execute_tool function is defined elsewhere)\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                \n",
    "                # Add the tool result to the conversation\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_id,\n",
    "                    \"content\": json.dumps(result) if not isinstance(result, str) else result\n",
    "                })\n",
    "            \n",
    "            # Make another API call with the updated conversation including tool results\n",
    "            response = client.chat.completions.create(\n",
    "                max_tokens=2024,\n",
    "                model='gpt-4o',\n",
    "                tools=tools_openai,\n",
    "                tool_choice='auto',\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            # Check if this response has only text content (no more tool calls)\n",
    "            if not response.choices[0].message.tool_calls:\n",
    "                print(response.choices[0].message.content)\n",
    "                process_query = False\n",
    "                \n",
    "        else:\n",
    "            # Assistant provided a text response (no tool calls)\n",
    "            if assistant_message.content:\n",
    "                print(assistant_message.content)\n",
    "            process_query = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f88e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 papers on attention in transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Narendra Modi is an Indian politician who has been serving as the Prime Minister of India since May 2014. He is a member of the Bharatiya Janata Party (BJP) and the Rashtriya Swayamsevak Sangh (RSS), a Hindu nationalist volunteer organization. Here are some key points about Narendra Modi:\n",
      "\n",
      "1. **Early Life and Education**: Narendra Damodardas Modi was born on September 17, 1950, in Vadnagar, Gujarat, India. He was raised in a modest family and helped his father sell tea as a child. Modi earned a Masterâ€™s degree in Political Science from Gujarat University.\n",
      "\n",
      "2. **Political Career**:\n",
      "   - **Chief Minister of Gujarat**: Modi served as the Chief Minister of the Indian state of Gujarat from 2001 to 2014. During his tenure, he was credited with fostering economic growth and infrastructure development but faced criticism for his handling of the 2002 Gujarat riots.\n",
      "   - **Prime Minister of India**: Modi led the BJP to a landslide victory in the 2014 general elections and became the 14th Prime Minister of India. He was re-elected in 2019 with an even larger majority.\n",
      "\n",
      "3. **Policies and Initiatives**: \n",
      "   - Modi's government has focused on economic reforms, digitization, infrastructure development, and initiatives like \"Make in India,\" \"Digital India,\" and \"Swachh Bharat Abhiyan\" (Clean India Mission).\n",
      "   - His government implemented the Goods and Services Tax (GST) and undertook a controversial demonetization policy in 2016.\n",
      "\n",
      "4. **Foreign Policy**: Modi has emphasized enhancing India's global standing, engaging with world leaders, and participating in international forums. He has fostered closer ties with various countries, including the US, Japan, and European nations.\n",
      "\n",
      "5. **Controversies**: Modi's tenure has not been without controversy. His government has faced criticism over issues such as religious tensions, freedom of speech, and policies perceived as nationalist. The passage of the Citizenship Amendment Act (CAA) in 2019, which sparked protests across the country, is one significant example.\n",
      "\n",
      "6. **Impact and Legacy**: Modi's leadership style and development agenda have made him a polarizing figure. Supporters praise his vision and governance, while critics often point to concerns over inclusivity and human rights.\n",
      "\n",
      "As a prominent leader on the global stage, Modi continues to shape India's domestic and foreign policies.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df7890-4b4c-4ec9-b06f-abc8c4a290e8",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34ee2d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b> To Access the <code>requirements.txt</code> file or the <code>papers</code> folder: </b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em> and finally 3) click on <em>\"L3\"</em>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5135e-01c3-4632-9f83-a1e6dd811049",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
